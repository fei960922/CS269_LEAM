{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run_python_code.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"c2HHoXjaa5BB","colab_type":"code","colab":{}},"source":["# The code starting from here is for setting up the environment of Google colab\n","# We need to connect google colab to google drive so that we can save the files and call scripts in the google drive\n","# We also need to install the related package: for example allennlp\n","# There will be an indicator to show where this code part ends\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HGTooC56pqnc","colab_type":"code","outputId":"3a3e4791-52d3-446e-b9cd-0e664c6369c8","executionInfo":{"status":"ok","timestamp":1559433554019,"user_tz":420,"elapsed":20712,"user":{"displayName":"YAXUAN ZHU","photoUrl":"","userId":"17993149116436288201"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eCRKbcMKq0n0","colab_type":"code","outputId":"445ce44d-b46c-4e7e-dee1-1f5587df67bb","executionInfo":{"status":"ok","timestamp":1559433573792,"user_tz":420,"elapsed":17240,"user":{"displayName":"YAXUAN ZHU","photoUrl":"","userId":"17993149116436288201"}},"colab":{"base_uri":"https://localhost:8080/","height":134}},"source":["# Install a Drive FUSE wrapper.\n","# https://github.com/astrada/google-drive-ocamlfuse\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse"],"execution_count":2,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 130911 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.3-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c7PP0Vqbq9zE","colab_type":"code","colab":{}},"source":["# Generate auth tokens for Colab\n","from google.colab import auth\n","auth.authenticate_user()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RVU8QJ-RrI3h","colab_type":"code","outputId":"4eb070dc-e20a-4fa5-80c7-af6ad0c90dcc","executionInfo":{"status":"ok","timestamp":1559433636992,"user_tz":420,"elapsed":4315,"user":{"displayName":"YAXUAN ZHU","photoUrl":"","userId":"17993149116436288201"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Generate creds for the Drive FUSE library.\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["··········\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h5wRuInorekl","colab_type":"code","colab":{}},"source":["# Create a directory and mount Google Drive using that directory.\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"twjEOTgzriX8","colab_type":"code","colab":{}},"source":["# http://pytorch.org/\n","from os import path\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","\n","accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n","\n","!pip3 install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TB5TLvdYjotL","colab_type":"code","outputId":"ceaf47a8-857b-4b54-b5aa-47faa9f8b276","executionInfo":{"status":"ok","timestamp":1559433648298,"user_tz":420,"elapsed":4168,"user":{"displayName":"YAXUAN ZHU","photoUrl":"","userId":"17993149116436288201"}},"colab":{"base_uri":"https://localhost:8080/","height":151}},"source":["!pip install overrides"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Collecting overrides\n","  Downloading https://files.pythonhosted.org/packages/de/55/3100c6d14c1ed177492fcf8f07c4a7d2d6c996c0a7fc6a9a0a41308e7eec/overrides-1.9.tar.gz\n","Building wheels for collected packages: overrides\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/8d/52/86/e5a83b1797e7d263b458d2334edd2704c78508b3eea9323718\n","Successfully built overrides\n","Installing collected packages: overrides\n","Successfully installed overrides-1.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"178BrPcyjt3z","colab_type":"code","outputId":"62e128ff-eb11-486b-ea3b-7d74b73bf1a9","executionInfo":{"status":"ok","timestamp":1559433705067,"user_tz":420,"elapsed":54682,"user":{"displayName":"YAXUAN ZHU","photoUrl":"","userId":"17993149116436288201"}},"colab":{"base_uri":"https://localhost:8080/","height":2342}},"source":["!pip install allennlp"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Collecting allennlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/8c/72b14d20c9cbb0306939ea41109fc599302634fd5c59ccba1a659b7d0360/allennlp-0.8.4-py3-none-any.whl (5.7MB)\n","\u001b[K     |████████████████████████████████| 5.7MB 3.3MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.21.0)\n","Collecting unidecode (from allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/39/53096f9217b057cb049fe872b7fc7ce799a1a89b76cf917d9639e7a558b5/Unidecode-1.0.23-py2.py3-none-any.whl (237kB)\n","\u001b[K     |████████████████████████████████| 245kB 57.9MB/s \n","\u001b[?25hCollecting conllu==0.11 (from allennlp)\n","  Downloading https://files.pythonhosted.org/packages/d4/2c/856344d9b69baf5b374c395b4286626181a80f0c2b2f704914d18a1cea47/conllu-0.11-py2.py3-none-any.whl\n","Collecting numpydoc>=0.8.0 (from allennlp)\n","  Downloading https://files.pythonhosted.org/packages/6a/f3/7cfe4c616e4b9fe05540256cc9c6661c052c8a4cec2915732793b36e1843/numpydoc-0.9.1.tar.gz\n","Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.4)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.8.0)\n","Requirement already satisfied: gevent>=1.3.6 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.5)\n","Collecting parsimonious>=0.8.0 (from allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 27.1MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.28.1)\n","Requirement already satisfied: overrides in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.9)\n","Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.5.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.21.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.16.4)\n","Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.0.3)\n","Collecting awscli>=1.11.91 (from allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/df/edd5e30bd7b7e6ffc541f44b922424d947be06b56fceb0d414b4164268ab/awscli-1.16.169-py2.py3-none-any.whl (1.6MB)\n","\u001b[K     |████████████████████████████████| 1.6MB 46.2MB/s \n","\u001b[?25hCollecting flaky (from allennlp)\n","  Downloading https://files.pythonhosted.org/packages/02/42/cca66659a786567c8af98587d66d75e7d2b6e65662f8daab75db708ac35b/flaky-3.5.3-py2.py3-none-any.whl\n","Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.0.3)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.9.157)\n","Collecting ftfy (from allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/86/df789c5834f15ae1ca53a8d4c1fc4788676c2e32112f6a786f2625d9c6e6/ftfy-5.5.1-py3-none-any.whl (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 28.9MB/s \n","\u001b[?25hRequirement already satisfied: spacy<2.2,>=2.0.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.0.18)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2018.9)\n","Collecting responses>=0.7 (from allennlp)\n","  Downloading https://files.pythonhosted.org/packages/d1/5a/b887e89925f1de7890ef298a74438371ed4ed29b33def9e6d02dc6036fd8/responses-0.10.6-py2.py3-none-any.whl\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.3.0)\n","Requirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.3.0)\n","Collecting tensorboardX>=1.2 (from allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/57/2f0a46538295b8e7f09625da6dd24c23f9d0d7ef119ca1c33528660130d5/tensorboardX-1.7-py2.py3-none-any.whl (238kB)\n","\u001b[K     |████████████████████████████████| 245kB 50.1MB/s \n","\u001b[?25hCollecting jsonpickle (from allennlp)\n","  Downloading https://files.pythonhosted.org/packages/07/07/c157520a3ebd166c8c24c6ae0ecae7c3968eb4653ff0e5af369bb82f004d/jsonpickle-1.2-py2.py3-none-any.whl\n","Collecting word2number>=1.1 (from allennlp)\n","  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n","Collecting flask-cors>=3.0.7 (from allennlp)\n","  Downloading https://files.pythonhosted.org/packages/65/cb/683f71ff8daa3aea0a5cbb276074de39f9ab66d3fbb8ad5efb5bb83e90d2/Flask_Cors-3.0.7-py2.py3-none-any.whl\n","Collecting jsonnet>=0.10.0; sys_platform != \"win32\" (from allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/dc/3abd3971869a741d7acdba166d71d4f9366b6b53028dfd56f95de356af0f/jsonnet-0.12.1.tar.gz (240kB)\n","\u001b[K     |████████████████████████████████| 245kB 42.3MB/s \n","\u001b[?25hCollecting pytorch-pretrained-bert>=0.6.0 (from allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\u001b[K     |████████████████████████████████| 133kB 54.2MB/s \n","\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2019.3.9)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2.8)\n","Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp) (1.8.5)\n","Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp) (2.10.1)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.7.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.12.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.3.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (7.0.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (19.1.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.8.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (41.0.1)\n","Requirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent>=1.3.6->allennlp) (0.4.15)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp) (0.13.2)\n","Requirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (0.15.4)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (7.0)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (1.1.0)\n","Collecting rsa<=3.5.0,>=3.1.2 (from awscli>=1.11.91->allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/ae/baedc9cb175552e95f3395c43055a6a5e125ae4d48a1d7a924baca83e92e/rsa-3.4.2-py2.py3-none-any.whl (46kB)\n","\u001b[K     |████████████████████████████████| 51kB 29.3MB/s \n","\u001b[?25hRequirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (0.2.0)\n","Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (0.14)\n","Collecting botocore==1.12.159 (from awscli>=1.11.91->allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/bb/113f5083f145c41750d5b6f171a76c20f2e2b55a7bd9d02f55e849559619/botocore-1.12.159-py2.py3-none-any.whl (5.5MB)\n","\u001b[K     |████████████████████████████████| 5.5MB 36.9MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML<=3.13,>=3.10 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (3.13)\n","Collecting colorama<=0.3.9,>=0.2.5 (from awscli>=1.11.91->allennlp)\n","  Downloading https://files.pythonhosted.org/packages/db/c8/7dcf9dbcb22429512708fe3a547f8b6101c0d02137acbd892505aee57adf/colorama-0.3.9-py2.py3-none-any.whl\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.4.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.5.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.9.4)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->allennlp) (0.1.7)\n","Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (2.0.1)\n","Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (0.9.6)\n","Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (1.35)\n","Requirement already satisfied: regex==2018.01.10 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (2018.1.10)\n","Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (6.12.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (1.0.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (2.0.2)\n","Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (0.2.9)\n","Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (3.7.1)\n","Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.2.1)\n","Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.1.0)\n","Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.1.3)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (0.7.12)\n","Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.1.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (19.0)\n","Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.7.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->numpydoc>=0.8.0->allennlp) (1.1.1)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<=3.5.0,>=3.1.2->awscli>=1.11.91->allennlp) (0.4.5)\n","Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy<2.2,>=2.0.18->allennlp) (0.5.6)\n","Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy<2.2,>=2.0.18->allennlp) (1.10.11)\n","Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy<2.2,>=2.0.18->allennlp) (0.9.0.1)\n","Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy<2.2,>=2.0.18->allennlp) (0.4.3.2)\n","Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy<2.2,>=2.0.18->allennlp) (0.9.0)\n","Building wheels for collected packages: numpydoc, parsimonious, word2number, jsonnet\n","  Building wheel for numpydoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/51/30/d1/92a39ba40f21cb70e53f8af96eb98f002a781843c065406500\n","  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/b7/8d/e7/a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a\n","  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n","  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/f0/47/51/a178b15274ed0db775a1ae9c799ce31e511609c3ab75a7dec5\n","Successfully built numpydoc parsimonious word2number jsonnet\n","Installing collected packages: unidecode, conllu, numpydoc, parsimonious, rsa, botocore, colorama, awscli, flaky, ftfy, responses, tensorboardX, jsonpickle, word2number, flask-cors, jsonnet, pytorch-pretrained-bert, allennlp\n","  Found existing installation: rsa 4.0\n","    Uninstalling rsa-4.0:\n","      Successfully uninstalled rsa-4.0\n","  Found existing installation: botocore 1.12.157\n","    Uninstalling botocore-1.12.157:\n","      Successfully uninstalled botocore-1.12.157\n","Successfully installed allennlp-0.8.4 awscli-1.16.169 botocore-1.12.159 colorama-0.3.9 conllu-0.11 flaky-3.5.3 flask-cors-3.0.7 ftfy-5.5.1 jsonnet-0.12.1 jsonpickle-1.2 numpydoc-0.9.1 parsimonious-0.8.1 pytorch-pretrained-bert-0.6.2 responses-0.10.6 rsa-3.4.2 tensorboardX-1.7 unidecode-1.0.23 word2number-1.1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["rsa"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"n9n88J4ai91U","colab_type":"code","outputId":"2acc10cd-546e-4caf-a5ba-266e325e67dc","executionInfo":{"status":"ok","timestamp":1559434103230,"user_tz":420,"elapsed":1471,"user":{"displayName":"YAXUAN ZHU","photoUrl":"","userId":"17993149116436288201"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","!ls\n","os.chdir('./drive/269')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["adc.json  drive  gdrive  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F8LQ0HiGbjyg","colab_type":"code","colab":{}},"source":["# Here we end the code for environment setting and begin the main part of the code\n","# In this code, we use ELMO as word embedding and LEAM as our model\n","# The tutorial of AllenNLP is http://mlexplained.com/2019/01/30/an-in-depth-tutorial-to-allennlp-from-basics-to-elmo-and-bert/\n","# In this tutorial there is also instructions about how to change ELMO to BERT\n","# to change the model to BERT, code need to be changed includes following codes in this notebook, model.py  maybe also trainer.py "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"udk9ciQFkRy-","colab_type":"code","colab":{}},"source":["import os\n","from main import main\n","from src.model import *\n","from src.utils import *\n","from src.trainer import *"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qYUYnGDdkyNw","colab_type":"code","colab":{}},"source":["# we first deal with the data\n","# to satisfy the requirements of AllenNLP api, we first save our data to pickle file\n","if not os.path.exists('train.pickle') or not os.path.exists('test.pickle') or not os.path.exists('class_name.pickle'):    \n","    data_dir = 'data/reuters'\n","    vocab_url = os.path.join(data_dir, 'vocab.pkl')\n","    train_url = os.path.join(data_dir, 'train')\n","    test_url = os.path.join(data_dir, 'test')\n","    vocab = pickle.load(open(vocab_url, 'rb'))\n","    vocab = list(zip(*sorted(vocab.items(), key=lambda x: x[1])))[0]\n","    vocab_size = len(vocab)\n","\n","    train_set, train_labels, class_names = dataset(train_url)\n","    test_set, test_labels, _ = dataset(test_url)\n","\n","\n","\n","    train_text = []\n","    for idx_list in train_set:\n","        s = \"\"\n","        for idx in idx_list:\n","            s += vocab[idx] + \" \" \n","        train_text.append(s)\n","\n","    test_text = []\n","    for idx_list in test_set:\n","        s = \"\"\n","        for idx in idx_list:\n","            s += vocab[idx] + \" \" \n","        test_text.append(s)\n","    train = {'text': train_text,\n","            'id': np.arange(len(train_text)),\n","            'labels': train_labels}\n","    with open('train.pickle', 'wb') as handle:\n","        pickle.dump(train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    test = {'text': test_text,\n","            'id': np.arange(len(test_text)),\n","            'labels': test_labels}\n","    with open('test.pickle', 'wb') as handle:\n","        pickle.dump(test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    class_name = {'name': class_names} \n","    with open('class_name.pickle', 'wb') as handle:\n","        pickle.dump(class_name, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDbDvkfJjLqj","colab_type":"code","colab":{}},"source":["from pathlib import Path\n","from typing import *\n","import torch\n","import torch.optim as optim\n","import numpy as np\n","import pandas as pd\n","import pickle\n","from functools import partial\n","from overrides import overrides\n","\n","from allennlp.data import Instance\n","from allennlp.data.token_indexers import TokenIndexer\n","from allennlp.data.tokenizers import Token\n","from allennlp.nn import util as nn_util\n","from allennlp.data.vocabulary import Vocabulary\n","from allennlp.data.dataset_readers import DatasetReader"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AnBmubqllMgt","colab_type":"code","outputId":"9303a631-c742-4527-d66b-8a97503a2441","executionInfo":{"status":"ok","timestamp":1559434341616,"user_tz":420,"elapsed":2149,"user":{"displayName":"YAXUAN ZHU","photoUrl":"","userId":"17993149116436288201"}},"colab":{"base_uri":"https://localhost:8080/","height":252}},"source":["# allennlp API for data preprocessing \n","from allennlp.data.fields import TextField, MetadataField, ArrayField\n","\n","class JigsawDatasetReader(DatasetReader):\n","    def __init__(self, tokenizer: Callable[[str], List[str]]=lambda x: x.split(),\n","                 token_indexers: Dict[str, TokenIndexer] = None,\n","                 max_seq_len: Optional[int]=80) -> None:\n","        super().__init__(lazy=False)\n","        self.tokenizer = tokenizer\n","        self.token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n","        self.max_seq_len = max_seq_len\n","\n","    @overrides\n","    def text_to_instance(self, tokens: List[Token], id: str,\n","                         labels: np.ndarray) -> Instance:\n","        sentence_field = TextField(tokens, self.token_indexers)\n","        fields = {\"tokens\": sentence_field}\n","        \n","        id_field = MetadataField(id)\n","        fields[\"id\"] = id_field\n","        \n","        label_field = ArrayField(array=labels)\n","        fields[\"label\"] = label_field\n","\n","        return Instance(fields)\n","    \n","    @overrides\n","    def _read(self, file_path: str) -> Iterator[Instance]:\n","        with open(file_path, 'rb') as handle:\n","            b = pickle.load(handle)\n","        text = b['text']\n","        idx = b['id']\n","        labels = b['labels']\n","        assert len(text) == len(idx) and len(text) == len(labels)\n","        for i in range(len(text)):\n","            yield self.text_to_instance(\n","                [Token(x) for x in self.tokenizer(text[i])],\n","                idx[i], labels[i],\n","            )\n","from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter\n","from allennlp.data.token_indexers.elmo_indexer import ELMoCharacterMapper, ELMoTokenCharactersIndexer\n","\n","# the token indexer is responsible for mapping tokens to integers\n","token_indexer = ELMoTokenCharactersIndexer()\n","\n","reader = JigsawDatasetReader(\n","    token_indexers={\"tokens\": token_indexer}\n",")\n","with open('class_name.pickle', 'rb') as handle:\n","     tmp = pickle.load(handle)\n","class_names = tmp['name']\n","print(class_names)\n","\n","train_ds, test_ds = (reader.read(fname) for fname in [\"train.pickle\", \"test.pickle\"])\n","val_ds = None\n","vocab = Vocabulary()\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["129it [00:00, 834.03it/s]"],"name":"stderr"},{"output_type":"stream","text":["['acq' 'alum' 'barley' 'bop' 'carcass' 'castor-oil' 'cocoa' 'coconut'\n"," 'coconut-oil' 'coffee' 'copper' 'copra-cake' 'corn' 'cotton' 'cotton-oil'\n"," 'cpi' 'cpu' 'crude' 'dfl' 'dlr' 'dmk' 'earn' 'fuel' 'gas' 'gnp' 'gold'\n"," 'grain' 'groundnut' 'groundnut-oil' 'heat' 'hog' 'housing' 'income'\n"," 'instal-debt' 'interest' 'ipi' 'iron-steel' 'jet' 'jobs' 'l-cattle'\n"," 'lead' 'lei' 'lin-oil' 'livestock' 'lumber' 'meal-feed' 'money-fx'\n"," 'money-supply' 'naphtha' 'nat-gas' 'nickel' 'nkr' 'nzdlr' 'oat' 'oilseed'\n"," 'orange' 'palladium' 'palm-oil' 'palmkernel' 'pet-chem' 'platinum'\n"," 'potato' 'propane' 'rand' 'rape-oil' 'rapeseed' 'reserves' 'retail'\n"," 'rice' 'rubber' 'rye' 'ship' 'silver' 'sorghum' 'soy-meal' 'soy-oil'\n"," 'soybean' 'strategic-metal' 'sugar' 'sun-meal' 'sun-oil' 'sunseed' 'tea'\n"," 'tin' 'trade' 'veg-oil' 'wheat' 'wpi' 'yen' 'zinc']\n"],"name":"stdout"},{"output_type":"stream","text":["6215it [00:01, 3468.68it/s]\n","1554it [00:00, 8518.76it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"loO0U_kEmTQo","colab_type":"code","outputId":"aeb2ab02-dc03-4552-858b-5a9d41ea1ef5","executionInfo":{"status":"ok","timestamp":1559321043349,"user_tz":420,"elapsed":13737,"user":{"displayName":"YAXUAN ZHU","photoUrl":"","userId":"17993149116436288201"}},"colab":{"base_uri":"https://localhost:8080/","height":1277}},"source":["from allennlp.data.iterators import BucketIterator\n","iterator = BucketIterator(batch_size=30, sorting_keys=[(\"tokens\", \"num_tokens\")])\n","iterator.index_with(vocab)\n","model = Leam_Classifier(len(class_names), 256, 256, 10, \n","                            n_layer=1, dropout_rate=0.5, embpath=None, label_att=True, multilabel=True)\n","model.load_state_dict(torch.load('model1.pth'))\n","trainer = Trainer(iterator, batch_size=30, num_epoches=50, learning_rate=3e-4, valid_freq=10, model_type='embed')\n","trainer.set_validation(test_ds)\n","trainer.init_model(model)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Leam_Classifier(\n","  (embedding): Embedding(\n","    (word_embeddings): BasicTextFieldEmbedder(\n","      (token_embedder_tokens): ElmoTokenEmbedder(\n","        (_elmo): Elmo(\n","          (_elmo_lstm): _ElmoBiLm(\n","            (_token_embedder): _ElmoCharacterEncoder(\n","              (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n","              (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n","              (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n","              (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n","              (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n","              (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n","              (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n","              (_highways): Highway(\n","                (_layers): ModuleList(\n","                  (0): Linear(in_features=2048, out_features=4096, bias=True)\n","                )\n","              )\n","              (_projection): Linear(in_features=2048, out_features=128, bias=True)\n","            )\n","            (_elmo_lstm): ElmoLstm(\n","              (forward_layer_0): LstmCellWithProjection(\n","                (input_linearity): Linear(in_features=128, out_features=4096, bias=False)\n","                (state_linearity): Linear(in_features=128, out_features=4096, bias=True)\n","                (state_projection): Linear(in_features=1024, out_features=128, bias=False)\n","              )\n","              (backward_layer_0): LstmCellWithProjection(\n","                (input_linearity): Linear(in_features=128, out_features=4096, bias=False)\n","                (state_linearity): Linear(in_features=128, out_features=4096, bias=True)\n","                (state_projection): Linear(in_features=1024, out_features=128, bias=False)\n","              )\n","              (forward_layer_1): LstmCellWithProjection(\n","                (input_linearity): Linear(in_features=128, out_features=4096, bias=False)\n","                (state_linearity): Linear(in_features=128, out_features=4096, bias=True)\n","                (state_projection): Linear(in_features=1024, out_features=128, bias=False)\n","              )\n","              (backward_layer_1): LstmCellWithProjection(\n","                (input_linearity): Linear(in_features=128, out_features=4096, bias=False)\n","                (state_linearity): Linear(in_features=128, out_features=4096, bias=True)\n","                (state_projection): Linear(in_features=1024, out_features=128, bias=False)\n","              )\n","            )\n","          )\n","          (_dropout): Dropout(p=0.5)\n","          (scalar_mix_0): ScalarMix(\n","            (scalar_parameters): ParameterList(\n","                (0): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]\n","                (1): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]\n","                (2): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (embedding_class): Embedding(90, 256)\n","    (conv): Conv1d(90, 90, kernel_size=(21,), stride=(1,), padding=(10,))\n","  )\n","  (classifier): Classifier(\n","    (classifier): Sequential(\n","      (0): Linear(in_features=256, out_features=256, bias=True)\n","      (1): ReLU(inplace)\n","      (2): Dropout(p=0.5)\n","      (3): Linear(in_features=256, out_features=90, bias=True)\n","    )\n","    (multilabel_loss): BCEWithLogitsLoss()\n","    (multiclass_loss): CrossEntropyLoss()\n","    (focal_loss): FocalLoss()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"4DEgnNjRn9OW","colab_type":"code","outputId":"3b1eef94-b63a-4785-ff65-70a42239fd63","executionInfo":{"status":"ok","timestamp":1559327811016,"user_tz":420,"elapsed":6757624,"user":{"displayName":"YAXUAN ZHU","photoUrl":"","userId":"17993149116436288201"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["# train the model and save the result\n","#trainer.model.load_state_dict(torch.load('model1.pth'))\n","\n","train_prob, train_beta = trainer.fit(train_ds, class_names)\n","torch.save(trainer.model.state_dict(), 'model.pth')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--- epoch: 0 ---\n","[0/50] loss_epoch : 0.01 val_match : 0.9324 match_epoch : 0.9508 val_hs : 0.8858 hs_epoch : 0.8537\n","--- epoch: 10 ---\n","[10/50] loss_epoch : 0.01 val_match : 0.9279 match_epoch : 0.9532 val_hs : 0.8817 hs_epoch : 0.8567\n","--- epoch: 20 ---\n","[20/50] loss_epoch : 0.01 val_match : 0.9363 match_epoch : 0.9533 val_hs : 0.8910 hs_epoch : 0.8447\n","--- epoch: 30 ---\n","[30/50] loss_epoch : 0.01 val_match : 0.9402 match_epoch : 0.9616 val_hs : 0.8907 hs_epoch : 0.8616\n","--- epoch: 40 ---\n","[40/50] loss_epoch : 0.01 val_match : 0.9408 match_epoch : 0.9638 val_hs : 0.8913 hs_epoch : 0.8649\n","Max_scores 0.9407979407979408 0.8913158056015198\n","training {'match': 0.9852564102564103, 'HS': 0.9574205713268212, 'f1': 0.9668891520956, 'HL': 0.0011004273504273505, 'exact_acc': 0.9227564102564103, 'min_acc': 0.9900641025641026, 'density_chosen': 0.01338497150997151, 'density': 0.01375534188034188, 'precision': 0.967348455942206, 'recal': 0.9743028846144864, 'no_pred': 0.007211538461538462}\n","validation {'match': 0.9414414414414415, 'HS': 0.8919593062450204, 'f1': 0.9070013891442463, 'HL': 0.002681252681252681, 'exact_acc': 0.8468468468468469, 'min_acc': 0.9806949806949807, 'density_chosen': 0.0122980122980123, 'density': 0.013506363506363507, 'precision': 0.9106851749708892, 'recal': 0.9191870441861788, 'no_pred': 0.043114543114543116}\n","1088\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wZIOS8cYQKPI","colab_type":"code","outputId":"e2c4dafb-36d4-4c0e-d7bf-ffd1407f6dfe","executionInfo":{"status":"ok","timestamp":1559327951074,"user_tz":420,"elapsed":12867,"user":{"displayName":"YAXUAN ZHU","photoUrl":"","userId":"17993149116436288201"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# here we load the pretrained model intorch.save(trainer.model.state_dict(), 'model.pth')\n","# trainer.model.load_state_dict(torch.load('model.pth'))\n","# first test it on the validation set to see wheter we have loaded in the right model\n","prob, _ = trainer.predict()\n","tmp = trainer.val_y.detach().cpu().numpy()\n","pred = prob > 0.5                \n","val_match = np.mean([(pred[i][tmp[i]==1]==1).any() for i in range(len(pred))])\n","val_hs = (((pred==1)*(tmp==1)).sum(1)/(((pred==1)+(tmp==1))>0).sum(1)).mean()\n","\n","print(\"Validation result: \",\n","    \"val_match : %0.4f\" % val_match,\n","    \"val_hs : %0.4f\" % val_hs\n","  ) "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Validation result:  val_match : 0.9408 val_hs : 0.8913\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ujxVFbXzwP5o","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"GSuETaonRuP6","colab_type":"code","outputId":"72d3f4f1-8c7f-42c9-ea8d-561965d482f6","executionInfo":{"status":"ok","timestamp":1559328008647,"user_tz":420,"elapsed":53043,"user":{"displayName":"YAXUAN ZHU","photoUrl":"","userId":"17993149116436288201"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["# load in the testset\n","\n","if not os.path.exists('task.pickle'):\n","  task_url = os.path.join(data_dir, 'task')\n","  seq_task, task_labels, _ = dataset(task_url, monitor=False)\n","  vocab = pickle.load(open(vocab_url, 'rb'))\n","  vocab = list(zip(*sorted(vocab.items(), key=lambda x: x[1])))[0]\n","  task_text = []\n","  for idx_list in seq_task:\n","      s = \"\"\n","      for idx in idx_list:\n","          s += vocab[idx] + \" \" \n","      task_text.append(s)\n","  task = {'text': task_text,\n","          'id': np.arange(len(task_text)),\n","          'labels': task_labels}\n","  with open('task.pickle', 'wb') as handle:\n","      pickle.dump(task, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","task_ds = reader.read('task.pickle')\n","trainer.set_validation(task_ds)\n","prob, _ = trainer.predict()\n","tmp = trainer.val_y.detach().cpu().numpy()\n","pred = prob > 0.5                \n","test_match = np.mean([(pred[i][tmp[i]==1]==1).any() for i in range(len(pred))])\n","test_hs = (((pred==1)*(tmp==1)).sum(1)/(((pred==1)+(tmp==1))>0).sum(1)).mean()\n","\n","print(\"testing result: \",\n","    \"test_match : %0.4f\" % test_match,\n","    \"test_hs : %0.4f\" % test_hs\n","  ) \n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["3019it [00:01, 1906.24it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["testing result:  test_match : 0.9156 test_hs : 0.8540\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3OR96nqwNPZk","colab_type":"code","outputId":"e9fce6a2-ad88-4dfe-fd5b-ba29c934fa69","executionInfo":{"status":"ok","timestamp":1559328345285,"user_tz":420,"elapsed":42070,"user":{"displayName":"YAXUAN ZHU","photoUrl":"","userId":"17993149116436288201"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# seems the original code (code used when doing this experiments) doesn't save the final model to trainer.model\n","# so here we manually load the model in trainer and do evaluation here\n","trainer.init_model(model)\n","trainer.set_validation(task_ds)\n","prob, _ = trainer.predict()\n","tmp = trainer.val_y.detach().cpu().numpy()\n","pred = prob > 0.5                \n","test_match = np.mean([(pred[i][tmp[i]==1]==1).any() for i in range(len(pred))])\n","test_hs = (((pred==1)*(tmp==1)).sum(1)/(((pred==1)+(tmp==1))>0).sum(1)).mean()\n","\n","print(\"testing result: \",\n","    \"test_match : %0.4f\" % test_match,\n","    \"test_hs : %0.4f\" % test_hs\n","  ) \n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["testing result:  test_match : 0.9162 test_hs : 0.8686\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x4xUik-tNso_","colab_type":"code","colab":{}},"source":["torch.save(model.state_dict(), 'model.pth')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"evY875_4N4n8","colab_type":"code","outputId":"8bd47cfe-22e8-435f-e7e7-9e277379896a","executionInfo":{"status":"error","timestamp":1559345473739,"user_tz":420,"elapsed":15861350,"user":{"displayName":"YAXUAN ZHU","photoUrl":"","userId":"17993149116436288201"}},"colab":{"base_uri":"https://localhost:8080/","height":732}},"source":["# here we try to use ELMO without LEAM\n","from allennlp.data.iterators import BucketIterator\n","iterator = BucketIterator(batch_size=30, sorting_keys=[(\"tokens\", \"num_tokens\")])\n","iterator.index_with(vocab)\n","model = Leam_Classifier(len(class_names), 256, 256, 10, \n","                            n_layer=1, dropout_rate=0.5, embpath=None, label_att=False, multilabel=True)\n","#model.load_state_dict(torch.load('model1.pth'))\n","trainer = Trainer(iterator, batch_size=30, num_epoches=120, learning_rate=1e-3, valid_freq=10, model_type='noembed')\n","trainer.set_validation(test_ds)\n","trainer.init_model(model)\n","train_prob = trainer.fit(train_ds, class_names)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--- epoch: 0 ---\n","[0/120] loss_epoch : 0.08 val_match : 0.3115 match_epoch : 0.2290 val_hs : 0.3108 hs_epoch : 0.2159\n","--- epoch: 10 ---\n","[10/120] loss_epoch : 0.02 val_match : 0.6898 match_epoch : 0.6981 val_hs : 0.6499 hs_epoch : 0.6071\n","--- epoch: 20 ---\n","[20/120] loss_epoch : 0.02 val_match : 0.7529 match_epoch : 0.7377 val_hs : 0.7089 hs_epoch : 0.6256\n","--- epoch: 30 ---\n","[30/120] loss_epoch : 0.02 val_match : 0.7812 match_epoch : 0.7987 val_hs : 0.7327 hs_epoch : 0.6969\n","--- epoch: 40 ---\n","[40/120] loss_epoch : 0.01 val_match : 0.7825 match_epoch : 0.8232 val_hs : 0.7328 hs_epoch : 0.6995\n","--- epoch: 50 ---\n","[50/120] loss_epoch : 0.01 val_match : 0.7967 match_epoch : 0.8335 val_hs : 0.7467 hs_epoch : 0.6940\n","--- epoch: 60 ---\n","[60/120] loss_epoch : 0.01 val_match : 0.8063 match_epoch : 0.8462 val_hs : 0.7557 hs_epoch : 0.7162\n","--- epoch: 70 ---\n","[70/120] loss_epoch : 0.01 val_match : 0.8050 match_epoch : 0.8684 val_hs : 0.7549 hs_epoch : 0.7421\n","--- epoch: 80 ---\n","[80/120] loss_epoch : 0.01 val_match : 0.8127 match_epoch : 0.8674 val_hs : 0.7599 hs_epoch : 0.7257\n","--- epoch: 90 ---\n","[90/120] loss_epoch : 0.01 val_match : 0.8115 match_epoch : 0.8692 val_hs : 0.7619 hs_epoch : 0.7305\n","--- epoch: 100 ---\n","[100/120] loss_epoch : 0.01 val_match : 0.8282 match_epoch : 0.8870 val_hs : 0.7760 hs_epoch : 0.7604\n","--- epoch: 110 ---\n","[110/120] loss_epoch : 0.01 val_match : 0.8205 match_epoch : 0.8850 val_hs : 0.7690 hs_epoch : 0.7500\n","Max_scores 0.8281853281853282 0.7759782741925598\n","training {'match': 0.9323717948717949, 'HS': 0.8914511472323972, 'f1': 0.9048853393338688, 'HL': 0.0022756410256410254, 'exact_acc': 0.8466346153846154, 'min_acc': 0.9826923076923076, 'density_chosen': 0.0125, 'density': 0.013586182336182338, 'precision': 0.9054499262311763, 'recal': 0.917255418192061, 'no_pred': 0.0483974358974359}\n","validation {'match': 0.8281853281853282, 'HS': 0.7759782741925598, 'f1': 0.7917279524422381, 'HL': 0.0048405548405548405, 'exact_acc': 0.7297297297297297, 'min_acc': 0.9613899613899614, 'density_chosen': 0.01118976118976119, 'density': 0.01367081367081367, 'precision': 0.7955353312496168, 'recal': 0.8046332046324394, 'no_pred': 0.12290862290862291}\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-374cca7f21c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_beta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_no_LEAM.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}]},{"cell_type":"code","metadata":{"id":"9mZl3DvmPF08","colab_type":"code","outputId":"a3c4c2d8-1396-4fe5-d8f2-1ee0e4e5d4bf","executionInfo":{"status":"ok","timestamp":1559345581398,"user_tz":420,"elapsed":20271,"user":{"displayName":"YAXUAN ZHU","photoUrl":"","userId":"17993149116436288201"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["torch.save(trainer.model.state_dict(), 'model_no_LEAM.pth')\n","prob, _ = trainer.predict()\n","tmp = trainer.val_y.detach().cpu().numpy()\n","pred = prob > 0.5                \n","val_match = np.mean([(pred[i][tmp[i]==1]==1).any() for i in range(len(pred))])\n","val_hs = (((pred==1)*(tmp==1)).sum(1)/(((pred==1)+(tmp==1))>0).sum(1)).mean()\n","\n","print(\"Validation result: \",\n","    \"val_match : %0.4f\" % val_match,\n","    \"val_hs : %0.4f\" % val_hs\n","  ) "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Validation result:  val_match : 0.8282 val_hs : 0.7760\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FoXrjdLAPcRC","colab_type":"code","outputId":"f64a3735-ccc7-4bdd-ee9d-406c39bc8d3d","executionInfo":{"status":"ok","timestamp":1559345664035,"user_tz":420,"elapsed":45791,"user":{"displayName":"YAXUAN ZHU","photoUrl":"","userId":"17993149116436288201"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["task_ds = reader.read('task.pickle')\n","trainer.set_validation(task_ds)\n","prob, _ = trainer.predict()\n","tmp = trainer.val_y.detach().cpu().numpy()\n","pred = prob > 0.5                \n","test_match = np.mean([(pred[i][tmp[i]==1]==1).any() for i in range(len(pred))])\n","test_hs = (((pred==1)*(tmp==1)).sum(1)/(((pred==1)+(tmp==1))>0).sum(1)).mean()\n","\n","print(\"testing result: \",\n","    \"test_match : %0.4f\" % test_match,\n","    \"test_hs : %0.4f\" % test_hs\n","  ) \n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["3019it [00:01, 2525.56it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["testing result:  test_match : 0.7907 test_hs : 0.7389\n"],"name":"stdout"}]}]}